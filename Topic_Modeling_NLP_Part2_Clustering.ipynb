{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nafisur Rahman\n",
    "nafisur21@gmail.com<br>\n",
    "https://www.linkedin.com/in/nafisur-rahman"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering Problem in NLP\n",
    "* Identifying the genre of a book\n",
    "* Recognizing the themes or topics in an article\n",
    "* Topic modeling\n",
    "* Clustering text Data\n",
    "* Modeling Text Topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic Modeling in NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering text data (Article) using Kmeans algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recognizing the themes or topics in an article"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2:- Clustering\n",
    "In part1 we have saved all the article from given blogpost (http://doxydonkey.blogspot.in/) into a tab seperated file called \"allposts.csv\".<br>\n",
    "In this part, we are loading \"allposts.csv\" file into pandas dataframe and doing cluster analysis. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset=pd.read_csv('allposts.csv',sep='\\t',quoting=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SoftBank's $100 Billion Tech Fund Rankles VCs ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Quora tests video answers to steal Q&amp;A from Yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pittsburgh Welcomed Uber s Driverless Car Expe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"LeEco employees are being called to a Tuesday...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Why Did a Chinese Peroxide Company Pay $1 Bill...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                post\n",
       "0  SoftBank's $100 Billion Tech Fund Rankles VCs ...\n",
       "1  Quora tests video answers to steal Q&A from Yo...\n",
       "2  Pittsburgh Welcomed Uber s Driverless Car Expe...\n",
       "3  \"LeEco employees are being called to a Tuesday...\n",
       "4  Why Did a Chinese Peroxide Company Pay $1 Bill..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=dataset[['post']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3117"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3117 entries, 0 to 3116\n",
      "Data columns (total 1 columns):\n",
      "post    2792 non-null object\n",
      "dtypes: object(1)\n",
      "memory usage: 24.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing the missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2792"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=df.dropna()\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing column without any text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>575</th>\n",
       "      <td>\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1476</th>\n",
       "      <td>\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1479</th>\n",
       "      <td>\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1482</th>\n",
       "      <td>\"</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     post\n",
       "575     \"\n",
       "766     \"\n",
       "1476    \"\n",
       "1479    \"\n",
       "1482    \""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['post']=='\"'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "l=df[df['post']=='\"'].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2636"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=df.drop(labels=l)\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resetting the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2636"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.reset_index(drop=True)\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SoftBank's $100 Billion Tech Fund Rankles VCs ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Quora tests video answers to steal Q&amp;A from Yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pittsburgh Welcomed Uber s Driverless Car Expe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"LeEco employees are being called to a Tuesday...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Why Did a Chinese Peroxide Company Pay $1 Bill...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                post\n",
       "0  SoftBank's $100 Billion Tech Fund Rankles VCs ...\n",
       "1  Quora tests video answers to steal Q&A from Yo...\n",
       "2  Pittsburgh Welcomed Uber s Driverless Car Expe...\n",
       "3  \"LeEco employees are being called to a Tuesday...\n",
       "4  Why Did a Chinese Peroxide Company Pay $1 Bill..."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1=df\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NLP Preprocessing task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "import re\n",
    "from nltk.stem import LancasterStemmer\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "ls=WordNetLemmatizer()\n",
    "cstopwords=set(stopwords.words('english')+list(punctuation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2636"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_corpus=[]\n",
    "for i in range(0,len(df)):\n",
    "    review=re.sub('[^a-zA-Z]',' ',df['post'][i])\n",
    "    #review=df['post'][i]\n",
    "    review=[ls.lemmatize(w) for w in word_tokenize(str(review).lower()) if w not in cstopwords]\n",
    "    review=' '.join(review)\n",
    "    text_corpus.append(review)\n",
    "    \n",
    "len(text_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NLP Features extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv=CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X1=cv.fit_transform(text_corpus).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2636, 19426)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2636, 10919)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidfvec=TfidfVectorizer(max_df=0.5,min_df=2,stop_words='english')\n",
    "X2=tfidfvec.fit_transform(text_corpus).toarray()\n",
    "X2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kmean Clustering Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from nltk.probability import FreqDist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finding number of cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "wcss=[]\n",
    "for i in range(1,10):\n",
    "    kmeans=KMeans(n_clusters=i)\n",
    "    kmeans.fit(X1)\n",
    "    wcss.append(kmeans.inertia_)\n",
    "    \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.plot(range(1,10),wcss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For simplicity we are only taking number of cluster=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 2, ..., 0, 2, 2])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "km=KMeans(n_clusters=3)\n",
    "km.fit(X1)\n",
    "km.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post</th>\n",
       "      <th>labels</th>\n",
       "      <th>processed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SoftBank's $100 Billion Tech Fund Rankles VCs ...</td>\n",
       "      <td>2</td>\n",
       "      <td>softbank billion tech fund rankles vcs valuati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Quora tests video answers to steal Q&amp;A from Yo...</td>\n",
       "      <td>1</td>\n",
       "      <td>quora test video answer steal q youtube newly ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pittsburgh Welcomed Uber s Driverless Car Expe...</td>\n",
       "      <td>2</td>\n",
       "      <td>pittsburgh welcomed uber driverless car experi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"LeEco employees are being called to a Tuesday...</td>\n",
       "      <td>2</td>\n",
       "      <td>leeco employee called tuesday meeting massive ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Why Did a Chinese Peroxide Company Pay $1 Bill...</td>\n",
       "      <td>0</td>\n",
       "      <td>chinese peroxide company pay billion talking c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                post  labels  \\\n",
       "0  SoftBank's $100 Billion Tech Fund Rankles VCs ...       2   \n",
       "1  Quora tests video answers to steal Q&A from Yo...       1   \n",
       "2  Pittsburgh Welcomed Uber s Driverless Car Expe...       2   \n",
       "3  \"LeEco employees are being called to a Tuesday...       2   \n",
       "4  Why Did a Chinese Peroxide Company Pay $1 Bill...       0   \n",
       "\n",
       "                                           processed  \n",
       "0  softbank billion tech fund rankles vcs valuati...  \n",
       "1  quora test video answer steal q youtube newly ...  \n",
       "2  pittsburgh welcomed uber driverless car experi...  \n",
       "3  leeco employee called tuesday meeting massive ...  \n",
       "4  chinese peroxide company pay billion talking c...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['labels']=km.labels_\n",
    "df1['processed']=text_corpus\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "km.n_clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most frequent words in each cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster : 0\n",
      "most common words : [('company', 2757), ('billion', 1841), ('percent', 1773), ('year', 1640), ('million', 1363), ('said', 1244), ('revenue', 1202), ('share', 1162), ('quarter', 944), ('business', 835), ('market', 732), ('investor', 705), ('sale', 686), (\"'\", 662), (',', 661), ('new', 642), ('last', 632), ('service', 566), ('china', 518), ('growth', 508), ('also', 479), ('analyst', 453), ('stock', 450), ('apple', 445), ('according', 434), ('profit', 422), ('first', 417), ('would', 410), ('inc', 403), ('uber', 402)]\n",
      "Cluster : 1\n",
      "most common words : [('facebook', 1203), ('ad', 887), ('user', 763), ('video', 491), ('company', 488), ('app', 437), ('google', 433), ('mobile', 378), ('new', 377), ('twitter', 375), ('said', 350), ('people', 338), ('like', 307), (\"'\", 293), (',', 292), ('service', 287), ('year', 272), ('also', 256), ('search', 253), ('million', 245), ('product', 239), ('percent', 237), ('business', 226), ('apps', 221), ('time', 219), ('one', 217), ('social', 209), ('data', 202), ('advertiser', 196), ('brand', 193)]\n",
      "Cluster : 2\n",
      "most common words : [('company', 2777), ('said', 1980), (\"'\", 1642), (',', 1641), ('year', 1411), ('service', 1225), ('new', 1215), ('million', 1141), ('google', 1121), ('amazon', 1106), ('apple', 1026), ('one', 939), ('also', 920), ('like', 868), ('billion', 862), ('product', 774), ('business', 772), ('percent', 743), ('time', 732), ('would', 726), ('online', 718), ('technology', 716), ('last', 694), ('market', 679), ('uber', 667), ('people', 663), ('user', 662), ('customer', 662), ('data', 636), ('china', 621)]\n"
     ]
    }
   ],
   "source": [
    "for i in range(km.n_clusters):\n",
    "    df2=df1[df['labels']==i]\n",
    "    df2=df2[['processed']]\n",
    "    words=word_tokenize(str(list(set([a for b in df2.values.tolist() for a in b]))))\n",
    "    dist=FreqDist(words)\n",
    "    print('Cluster :',i)\n",
    "    print('most common words :',dist.most_common(30))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most frequent unique words in each cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text={}\n",
    "for i,cluster in enumerate(km.labels_):\n",
    "    oneDocument = df1['processed'][i]\n",
    "    if cluster not in text.keys():\n",
    "        text[cluster] = oneDocument\n",
    "    else:\n",
    "        text[cluster] += oneDocument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.probability import FreqDist\n",
    "from collections import defaultdict\n",
    "from string import punctuation\n",
    "from heapq import nlargest\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_stopwords = set(stopwords.words('english') + list(punctuation)+[\"million\",\"billion\",\"year\",\"millions\",\"billions\",\"y/y\",\"'s\",\"''\",\"``\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "keywords = {}\n",
    "counts={}\n",
    "for cluster in range(3):\n",
    "    word_sent = word_tokenize(text[cluster].lower())\n",
    "    word_sent=[word for word in word_sent if word not in _stopwords]\n",
    "    freq = FreqDist(word_sent)\n",
    "    keywords[cluster] = nlargest(100, freq, key=freq.get)\n",
    "    counts[cluster]=freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unique_keys={}\n",
    "for cluster in range(3):   \n",
    "    other_clusters=list(set(range(3))-set([cluster]))\n",
    "    keys_other_clusters=set(keywords[other_clusters[0]]).union(set(keywords[other_clusters[1]]))\n",
    "    unique=set(keywords[cluster])-keys_other_clusters\n",
    "    unique_keys[cluster]=nlargest(10, unique, key=counts[cluster].get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: ['quarter',\n",
       "  'growth',\n",
       "  'analyst',\n",
       "  'stock',\n",
       "  'profit',\n",
       "  'valuation',\n",
       "  'cloud',\n",
       "  'cent',\n",
       "  'public',\n",
       "  'rose'],\n",
       " 1: ['facebook',\n",
       "  'ad',\n",
       "  'search',\n",
       "  'apps',\n",
       "  'social',\n",
       "  'advertiser',\n",
       "  'brand',\n",
       "  'advertising',\n",
       "  'feature',\n",
       "  'instagram'],\n",
       " 2: ['car',\n",
       "  'store',\n",
       "  'consumer',\n",
       "  'pay',\n",
       "  'system',\n",
       "  'startup',\n",
       "  'plan',\n",
       "  'payment',\n",
       "  'country',\n",
       "  'industry']}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_keys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topics Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Cluster 0= Related to startup and Fund raising plan\n",
    "2. Cluster 1= Stock performance related\n",
    "3. Cluster 2= Social media and advertising related"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
